{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "single_sentence.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-nOh1TKGFYm"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4JuHpDPGMRZ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/Drive/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h5_x5q7G9lJ"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import textwrap\n",
        "import progressbar\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_oJBtMQHHbo"
      },
      "source": [
        "f_train_CL = open(\"/content/Drive/MyDrive/Technical/RR/CL_train.json\", \"r\")\n",
        "f_test_CL = open(\"/content/Drive/MyDrive/Technical/RR/CL_test.json\", \"r\")\n",
        "f_test_IT = open(\"/content/Drive/MyDrive/Technical/RR/IT_test.json\", \"r\")\n",
        "f_train_IT = open(\"/content/Drive/MyDrive/Technical/RR/IT_train.json\", \"r\")\n",
        "\n",
        "data_tr_CL = json.load(f_train_CL)\n",
        "f_train_CL.close()\n",
        "data_te_CL = json.load(f_test_CL)\n",
        "f_test_CL.close()\n",
        "data_tr_IT = json.load(f_train_IT)\n",
        "f_train_IT.close()\n",
        "data_te_IT = json.load(f_test_IT)\n",
        "f_test_IT.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmPOURMYBcni"
      },
      "source": [
        "Make dev jason files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afanlUYIIONj"
      },
      "source": [
        "def df_maker(data, d_t):\n",
        "  docs = data.keys()\n",
        "  texts = []\n",
        "  labels = []\n",
        "  label_mapper = {}\n",
        "  if(d_t == \"compressed\"):\n",
        "    label_mapper = {\n",
        "        \"Fact\": 0,\n",
        "        \"ArgumentPetitioner\": 1,\n",
        "        \"ArgumentRespondent\": 1,\n",
        "        \"RulingByPresentCourt\": 2,\n",
        "        \"RulingByLowerCourt\": 3,\n",
        "        \"RatioOfTheDecision\": 4,\n",
        "        \"None\": -1,\n",
        "        \"Statute\": 5,\n",
        "        \"PrecedentReliedUpon\": 6,\n",
        "        \"PrecedentNotReliedUpon\": 6,\n",
        "        \"PrecedentOverruled\": 6,\n",
        "        \"Issue\": 0,\n",
        "        \"Dissent\": 0\n",
        "    }\n",
        "  if(d_t == \"full\"):\n",
        "    label_mapper = {\n",
        "        \"Fact\": 0,\n",
        "        \"ArgumentPetitioner\": 1,\n",
        "        \"ArgumentRespondent\": 2,\n",
        "        \"RulingByPresentCourt\": 3,\n",
        "        \"RulingByLowerCourt\": 4,\n",
        "        \"RatioOfTheDecision\": 5,\n",
        "        \"None\": 6,\n",
        "        \"Statute\": 7,\n",
        "        \"PrecedentReliedUpon\": 8,\n",
        "        \"PrecedentNotReliedUpon\": 9,\n",
        "        \"PrecedentOverruled\": 10,\n",
        "        \"Issue\": 11,\n",
        "        \"Dissent\": 12\n",
        "    }\n",
        "  for doc in docs:\n",
        "    for i,label in enumerate(data[doc][\"complete\"]):\n",
        "      if(label == \"None\" and d_t==\"compressed\"):\n",
        "        continue\n",
        "\n",
        "      texts.append(data[doc][\"sentences\"][i])\n",
        "      labels.append(label_mapper[label])\n",
        "\n",
        "  dict_tl = {\"text\": texts, \"label\": labels}\n",
        "  df = pd. DataFrame(dict_tl)\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc-aUFrGI7kw"
      },
      "source": [
        "d_type_start = \"compressed\"\n",
        "train_CL = df_maker(data_tr_CL, d_type_start)\n",
        "test_CL = df_maker(data_te_CL, d_type_start)\n",
        "train_IT = df_maker(data_tr_IT, d_type_start)\n",
        "test_IT = df_maker(data_te_IT, d_type_start)\n",
        "\n",
        "CL_train_set = train_CL\n",
        "CL_validation_set = train_CL\n",
        "CL_test_set = test_CL\n",
        "IT_train_set = train_IT\n",
        "IT_validation_set = train_IT\n",
        "IT_test_set = test_IT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMZEW0nOKDG6"
      },
      "source": [
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)}\n",
        "\n",
        "model_type = 'bert' ###--> CHANGE WHAT MODEL YOU WANT HERE!!! <--###\n",
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
        "model_name = 'bert-base-uncased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ0bhehnOCRV"
      },
      "source": [
        "def att_masking(input_ids):\n",
        "  attention_masks = []\n",
        "  for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)\n",
        "  return attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTSi1przOXPd"
      },
      "source": [
        "def input_id_maker(dataf, tokenizer):\n",
        "  input_ids = []\n",
        "  lengths = []\n",
        "  for i in progressbar.progressbar(range(len(dataf['text']))):\n",
        "    sen = dataf['text'].iloc[i]\n",
        "    sen = tokenizer.tokenize(sen)\n",
        "    #taking the last 510 tokens\n",
        "    #you can try out multiple combinations of input tokens as we did in the paper\n",
        "    if(len(sen) > 254):\n",
        "      sen = sen[len(sen)-254:]\n",
        "\n",
        "    encoded_sent = tokenizer.encode(sen, add_special_tokens=True)\n",
        "    input_ids.append(encoded_sent)\n",
        "    lengths.append(len(encoded_sent))\n",
        "\n",
        "  input_ids = pad_sequences(input_ids, maxlen=256, value=0, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "  return input_ids, lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yncexlXO0Wj"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbzlF6ZgO37F"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quVKy16SO9lC"
      },
      "source": [
        "CL_train_input_ids, _ = input_id_maker(CL_train_set, tokenizer)\n",
        "CL_validation_input_ids = CL_train_input_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZgTpIB1PRLE"
      },
      "source": [
        "IT_train_input_ids, _ = input_id_maker(IT_train_set, tokenizer)\n",
        "IT_validation_input_ids = IT_train_input_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzMDr38IPh3k"
      },
      "source": [
        "CL_train_attention_masks = att_masking(CL_train_input_ids)\n",
        "CL_validation_attention_masks = CL_train_attention_masks\n",
        "\n",
        "CL_train_labels = CL_train_set['label'].to_numpy().astype('int')\n",
        "CL_validation_labels = CL_train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJCy0ncxPza1"
      },
      "source": [
        "IT_train_attention_masks = att_masking(IT_train_input_ids)\n",
        "IT_validation_attention_masks = IT_train_attention_masks\n",
        "\n",
        "IT_train_labels = IT_train_set['label'].to_numpy().astype('int')\n",
        "IT_validation_labels = IT_train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bZ6zZlPP6G1"
      },
      "source": [
        "CL_test_input_ids, _ = input_id_maker(CL_test_set, tokenizer)\n",
        "CL_test_attention_masks = att_masking(CL_test_input_ids)\n",
        "CL_test_labels = CL_test_set['label'].to_numpy().astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjNxOJpoQJYf"
      },
      "source": [
        "IT_test_input_ids, _ = input_id_maker(IT_test_set, tokenizer)\n",
        "IT_test_attention_masks = att_masking(IT_test_input_ids)\n",
        "IT_test_labels = IT_test_set['label'].to_numpy().astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIpWNESDQWH2"
      },
      "source": [
        "#CL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj28uHgQQOvl"
      },
      "source": [
        "CL_train_inputs = CL_train_input_ids\n",
        "CL_validation_inputs = CL_validation_input_ids\n",
        "CL_train_masks = CL_train_attention_masks\n",
        "CL_validation_masks = CL_validation_attention_masks\n",
        "\n",
        "# IT_train_inputs = IT_train_input_ids\n",
        "# IT_validation_inputs = IT_validation_input_ids\n",
        "# IT_train_masks = IT_train_attention_masks\n",
        "# IT_validation_masks = IT_validation_attention_masks\n",
        "\n",
        "train_inputs = torch.tensor(CL_train_inputs)\n",
        "train_labels = torch.tensor(CL_train_labels)\n",
        "train_masks = torch.tensor(CL_train_masks)\n",
        "validation_inputs = torch.tensor(CL_validation_inputs)\n",
        "validation_labels = torch.tensor(CL_validation_labels)\n",
        "validation_masks = torch.tensor(CL_validation_masks)\n",
        "\n",
        "# train_inputs = torch.tensor(IT_train_inputs)\n",
        "# train_labels = torch.tensor(IT_train_labels)\n",
        "# train_masks = torch.tensor(IT_train_masks)\n",
        "# validation_inputs = torch.tensor(IT_validation_inputs)\n",
        "# validation_labels = torch.tensor(IT_validation_labels)\n",
        "# validation_masks = torch.tensor(IT_validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK2IXdisQiVc"
      },
      "source": [
        "batch_size = 16\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = RandomSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfKDfDuMQnoR"
      },
      "source": [
        "nl = 0\n",
        "if(d_type_start == \"full\"):\n",
        "  nl = 13\n",
        "else:\n",
        "  nl = 7\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=nl)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93JAEHA4REER"
      },
      "source": [
        "lr = 2e-5\n",
        "max_grad_norm = 1.0\n",
        "epochs = 3\n",
        "num_total_steps = len(train_dataloader)*epochs\n",
        "num_warmup_steps = 1000\n",
        "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=True)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = num_total_steps)\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "seed_val = 34\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpIW4t6URIcL"
      },
      "source": [
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}. '.format(step, len(train_dataloader)))\n",
        "\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "          outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "        logits = outputs[0]\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6IysiO0RS4M"
      },
      "source": [
        "prediction_inputs = torch.tensor(CL_test_input_ids)\n",
        "prediction_masks = torch.tensor(CL_test_attention_masks)\n",
        "prediction_labels = torch.tensor(CL_test_labels)\n",
        "\n",
        "# prediction_inputs = torch.tensor(IT_test_input_ids)\n",
        "# prediction_masks = torch.tensor(IT_test_attention_masks)\n",
        "# prediction_labels = torch.tensor(IT_test_labels)\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzc_C-xgSlgF"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "\n",
        "# Predict \n",
        "for (step, batch) in enumerate(prediction_dataloader):\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2niwlp7aStig"
      },
      "source": [
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)\n",
        "pred_flat = np.argmax(predictions, axis=1).flatten()\n",
        "labels_flat = true_labels.flatten()\n",
        "\n",
        "flat_accuracy(predictions,true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZdPHRvtSxrP"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# utility function to calculate metric scores\n",
        "def metrics_calculator(preds, test_labels):\n",
        "    cm = confusion_matrix(test_labels, preds)\n",
        "    TP = []\n",
        "    FP = []\n",
        "    FN = []\n",
        "    for i in range(0,nl):\n",
        "        summ = 0\n",
        "        for j in range(0,nl):\n",
        "            if(i!=j):\n",
        "                summ=summ+cm[i][j]\n",
        "\n",
        "        FN.append(summ)\n",
        "    for i in range(0,nl):\n",
        "        summ = 0\n",
        "        for j in range(0,nl):\n",
        "            if(i!=j):\n",
        "                summ=summ+cm[j][i]\n",
        "\n",
        "        FP.append(summ)\n",
        "    for i in range(0,nl):\n",
        "        TP.append(cm[i][i])\n",
        "    precision = []\n",
        "    recall = []\n",
        "    for i in range(0,nl):\n",
        "        precision.append(TP[i]/(TP[i] + FP[i]))\n",
        "        recall.append(TP[i]/(TP[i] + FN[i]))\n",
        "\n",
        "    macro_precision = sum(precision)/nl\n",
        "    macro_recall = sum(recall)/nl\n",
        "    micro_precision = sum(TP)/(sum(TP) + sum(FP))\n",
        "    micro_recall = sum(TP)/(sum(TP) + sum(FN))\n",
        "    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision + micro_recall)\n",
        "    macro_f1 = (2*macro_precision*macro_recall)/(macro_precision + macro_recall)\n",
        "    return macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1\n",
        "\n",
        "macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1 = metrics_calculator(pred_flat, labels_flat)\n",
        "print(macro_precision, macro_recall, macro_f1, micro_precision, micro_recall, micro_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wEqYXmyT00N"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels_flat, pred_flat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAKfmemkUHJT"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}