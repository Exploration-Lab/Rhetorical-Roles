{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce18a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "IT_train_path = 'IT_train.json'\n",
    "IT_test_path = 'IT_test.json'\n",
    "CL_train_path = 'CL_train.json'\n",
    "CL_test_path = 'CL_test.json'\n",
    "\n",
    "train_it = {}\n",
    "test_it = {}\n",
    "train_cl = {}\n",
    "test_cl = {}\n",
    "\n",
    "with open(IT_train_path, 'r') as f:\n",
    "    train_it = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "with open(IT_test_path, 'r') as f:\n",
    "    test_it = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open(CL_train_path, 'r') as f:\n",
    "    train_cl = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "with open(CL_test_path, 'r') as f:\n",
    "    test_cl = json.load(f)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2518e3c5",
   "metadata": {},
   "source": [
    "## Preparing Data in txt format(sentence tab label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432706f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_it = 'handcrafted_features/train_it/'\n",
    "train_path_cl = 'handcrafted_features/train_cl/'\n",
    "test_path_it = 'handcrafted_features/test_it/'\n",
    "test_path_cl = 'handcrafted_features/test_cl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a62596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in train_it.keys():\n",
    "    sentences = train_it[case]['sentences']\n",
    "    labels = train_it[case]['complete']\n",
    "    all_text = \"\"\n",
    "    for sent, label in zip(sentences, labels):\n",
    "        all_text += sent+\"\\t\"+label+\"\\n\"\n",
    "    with open(train_path_it+case, \"w\") as f:\n",
    "        f.write(all_text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a2ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in train_cl.keys():\n",
    "    sentences = train_cl[case]['sentences']\n",
    "    labels = train_cl[case]['complete']\n",
    "    all_text = \"\"\n",
    "    for sent, label in zip(sentences, labels):\n",
    "        all_text += sent+\"\\t\"+label+\"\\n\"\n",
    "    with open(train_path_cl+case, \"w\") as f:\n",
    "        f.write(all_text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in test_it.keys():\n",
    "    sentences = test_it[case]['sentences']\n",
    "    labels = test_it[case]['complete']\n",
    "    all_text = \"\"\n",
    "    for sent, label in zip(sentences, labels):\n",
    "        all_text += sent+\"\\t\"+label+\"\\n\"\n",
    "    with open(test_path_it+case, \"w\") as f:\n",
    "        f.write(all_text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f893ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in test_cl.keys():\n",
    "    sentences = test_cl[case]['sentences']\n",
    "    labels = test_cl[case]['complete']\n",
    "    all_text = \"\"\n",
    "    for sent, label in zip(sentences, labels):\n",
    "        all_text += sent+\"\\t\"+label+\"\\n\"\n",
    "    with open(test_path_cl+case, \"w\") as f:\n",
    "        f.write(all_text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a7707",
   "metadata": {},
   "source": [
    "## Getting Cue-NE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b222b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"handcrafted_features/train_cl/\"\n",
    "pathw = \"handcrafted_features/train_cl_ne/\"\n",
    "fr_ne = open(\"handcrafted-features-code/NE.txt\",\"r\")\n",
    "fr_cue = open(\"handcrafted-features-code/cue_phrases_saravanan.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627dca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hcf = []\n",
    "#count = {}\n",
    "print (\"pos tags\")\n",
    "for line in fr_ne.readlines():\n",
    "    line = line.rstrip(\"\\n\")\n",
    "    hcf.append(line)\n",
    "\n",
    "for line in fr_cue.readlines():\n",
    "    line = line.rstrip(\"\\n\")\n",
    "    hcf.append(line)\n",
    "print(hcf)\n",
    "print (\"file reading starts\")\n",
    "ctr = 0\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    url = os.path.join(path,file)\n",
    "    fr = open(url,\"r\")\n",
    "    ctr+=1\n",
    "    #print (url)\n",
    "    fw = open(os.path.join(pathw,file),\"w\")\n",
    "    \n",
    "    for line in fr.readlines():\n",
    "        labels = np.zeros(len(hcf),dtype='int32')\n",
    "        line = line.rstrip(\"\\n\\r\")\n",
    "        ls = line.split(\"\\t\")\n",
    "        sent = ls[0]\n",
    "        lab = ls[1]\n",
    "        for c in hcf:\n",
    "            if c in line:\n",
    "                ind = hcf.index(c)\n",
    "                labels[ind] = labels[ind]+1\n",
    "                \n",
    "        sum=0\n",
    "        for i in labels:\n",
    "            sum+=i\n",
    "        print(labels)\n",
    "        fw.write(sent+\"$$$\"+lab+\"$$$\")\n",
    "        for i in labels:\n",
    "            try:\n",
    "                fw.write(str(round(float(i)/float(sum),5))+\"$$$\")\n",
    "                \n",
    "            except:\n",
    "                fw.write(\"0.0\"+\"$$$\")\n",
    "        fw.write(\"\\n\")\n",
    "    fw.close()   \n",
    "    fr.close()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e1707",
   "metadata": {},
   "source": [
    "## Getting Layout Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_para_position(original_docs_path):\n",
    "    file_para_pos = {}\n",
    "    \n",
    "    for file in tqdm(os.listdir(original_docs_path)):\n",
    "        fr = open(os.path.join(original_docs_path,file),\"r\")\n",
    "        count=0\n",
    "        para_pos = {}\n",
    "        for line in fr.readlines():\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            line = line.split(\"\\t\")[0]\n",
    "            count+=1\n",
    "            para_pos [line] = count\n",
    "        \n",
    "        for k,v in para_pos.items():\n",
    "            norm_v = round(float(v)/float(count),5)\n",
    "            para_pos[k] = norm_v\n",
    "            \n",
    "        file_para_pos[file] = para_pos\n",
    "    \n",
    "    return file_para_pos\n",
    "\n",
    "\n",
    "def get_sentence_position(sent_split_docs_path):\n",
    "    file_sent_pos = {}\n",
    "    \n",
    "    for file in tqdm(os.listdir(sent_split_docs_path)):\n",
    "        fr = open(os.path.join(sent_split_docs_path,file),\"r\")\n",
    "        count=0\n",
    "        sent_pos = {}\n",
    "        for line in fr.readlines():\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            count+=1\n",
    "            sent_pos [line] = count\n",
    "        \n",
    "        for k,v in sent_pos.items():\n",
    "            norm_v = round(float(v)/float(count),5)\n",
    "            sent_pos[k] = norm_v\n",
    "            \n",
    "        file_sent_pos[file] = sent_pos\n",
    "        \n",
    "    return file_sent_pos\n",
    "  \n",
    "path_whole = \"handcrafted_features/test_cl/\"\n",
    "path_ss = \"handcrafted_features/test_cl/\"\n",
    "pathw = \"handcrafted_features/test_cl_layout/\"\n",
    "\n",
    "print(\"\\n\\n para pos \\n\\n\")\n",
    "para_pos = get_para_position(path_whole)\n",
    "\n",
    "print(\"\\n\\n sent pos \\n\\n\")\n",
    "sent_pos = get_sentence_position(path_ss)\n",
    "\n",
    "for file, sent_features in sent_pos.items():\n",
    "    fw = open(os.path.join(pathw,file),\"w\")\n",
    "    for line,sent_feats in sent_features.items():\n",
    "        line,label = line.split(\"\\t\")\n",
    "        for para, para_feats in para_pos[file].items():\n",
    "            if line in para:\n",
    "                para_feat = para_feats\n",
    "                break\n",
    "        fw.write(line+\"$$$\"+label+\"$$$\"+str(para_feat)+\"$$$\"+str(sent_feats)+\"\\n\")\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3460f12",
   "metadata": {},
   "source": [
    "## Getting POS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f79f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = \"handcrafted_features/train_cl/\"\n",
    "pathw = \"handcrafted_features/train_cl_pos/\"\n",
    "fr_pos = open(\"handcrafted-features-code/postags_list.txt\",\"r\")\n",
    "\n",
    "postags = []\n",
    "#count = {}\n",
    "print (\"pos tags\")\n",
    "for line in fr_pos.readlines():\n",
    "    line = line.rstrip(\"\\n\")\n",
    "    postags.append(line)\n",
    "\n",
    "print (\"file reading starts\")\n",
    "ctr = 0\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    url = os.path.join(path,file)\n",
    "    fr = open(url,\"r\")\n",
    "    ctr+=1\n",
    "    print (url)\n",
    "    fw = open(os.path.join(pathw,file),\"w\")\n",
    "    \n",
    "    for line in fr.readlines():\n",
    "        labels = np.zeros(len(postags),dtype='int32')\n",
    "        line = line.rstrip(\"\\n\\r\")\n",
    "        ls = line.split(\"\\t\")\n",
    "        sent = ls[0]\n",
    "        lab = ls[1]\n",
    "        tokens = nltk.word_tokenize(sent)\n",
    "        pos_list = nltk.pos_tag(tokens)\n",
    "        \n",
    "        for p in pos_list:\n",
    "            pos = p[1]\n",
    "            if pos in postags:\n",
    "                ind = postags.index(pos)\n",
    "                labels[ind] = labels[ind]+1\n",
    "        sum=0\n",
    "        for i in labels:\n",
    "            sum+=i\n",
    "        \n",
    "        fw.write(sent+\"$$$\"+lab+\"$$$\")\n",
    "        for i in labels:\n",
    "            try:\n",
    "                fw.write(str(round(float(i)/float(sum),5))+\"$$$\")\n",
    "            except:\n",
    "                fw.write(\"0.0\"+\"$$$\")\n",
    "        fw.write(\"\\n\")\n",
    "        \n",
    "    fw.close()   \n",
    "    fr.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd78846",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e28db",
   "metadata": {},
   "source": [
    "## Appending all the 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "layout_feats = \"handcrafted_features/test_cl_layout/\"\n",
    "pos_feats = \"handcrafted_features/test_cl_pos/\"\n",
    "cue_ne_feats = \"handcrafted_features/test_cl_ne/\"\n",
    "\n",
    "\n",
    "pathw_818 = \"handcrafted_features/test_cl_final/\"\n",
    "\n",
    "\n",
    "for file in os.listdir(layout_feats):\n",
    "    fr_lay = open(os.path.join(layout_feats,file),\"r\")\n",
    "    fr_pos = open(os.path.join(pos_feats,file),\"r\")\n",
    "    fr_cuene =  open(os.path.join(cue_ne_feats,file),\"r\")\n",
    "    \n",
    "    fw_818 = open(os.path.join(pathw_818,file),\"w\")\n",
    "\n",
    "    \n",
    "    lays = fr_lay.readlines()\n",
    "    pos = fr_pos.readlines()\n",
    "    cuene = fr_cuene.readlines()\n",
    "    \n",
    "    for i in range(len(lays)):\n",
    "        item1 = lays[i]\n",
    "        item2 = pos[i]\n",
    "        item3 = cuene[i]\n",
    "        \n",
    "        item1 = item1.rstrip(\"\\n\")\n",
    "        item2 = item2.rstrip(\"\\n\")\n",
    "        item3 = item3.rstrip(\"\\n\")\n",
    "\n",
    "        ls1 = item1.split(\"$$$\")\n",
    "        ls2 = item2.split(\"$$$\")\n",
    "        ls3 = item3.split(\"$$$\")\n",
    "        \n",
    "        sent = ls1[0].lstrip(\" \").rstrip(\" \")\n",
    "        lab = ls1[1].lstrip(\" \").rstrip(\" \")\n",
    "        \n",
    "        \n",
    "        f1 = ls1[2:]\n",
    "        f2 = ls2[2:]\n",
    "        f3 = ls3[2:]\n",
    "        \n",
    "        line  = sent+\"$$$\"+lab+\"$$$\"+\"$$$\".join(f1)+\"$$$\"+\"$$$\".join(f2)+\"$$$\"+\"$$$\".join(f3)+\"\\n\"\n",
    "        fw_818.write(sent+\"$$$\"+lab+\"$$$\"+\"$$$\".join(f1)+\"$$$\"+\"$$$\".join(f2)+\"$$$\"+\"$$$\".join(f3)+\"\\n\")\n",
    "\n",
    "    fw_818.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1dbd7c",
   "metadata": {},
   "source": [
    "## Getting final embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd27461",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inp = \"handcrafted_features/test_it_final/\"\n",
    "path_out = \"handcrafted_features/test_it_handcrafted/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "mapping['ArgumentPetitioner'] = 'Argument'\n",
    "mapping['ArgumentRespondent'] = 'Argument'\n",
    "mapping['Fact'] = 'Fact'\n",
    "mapping['Issue'] = 'Fact'\n",
    "mapping['PrecedentNotReliedUpon'] = 'Precedent'\n",
    "mapping['PrecedentReliedUpon'] = 'Precedent'\n",
    "mapping['PrecedentOverruled'] = 'Precedent'\n",
    "mapping['RatioOfTheDecision'] = 'RatioOfTheDecision'\n",
    "mapping['Statute'] = 'Statute'\n",
    "mapping['RulingByPresentCourt'] = 'RulingByPresentCourt'\n",
    "mapping['RulingByLowerCourt'] = 'RulingByLowerCourt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f40d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in os.listdir(path_inp):\n",
    "    all_text = \"\"\n",
    "    with open(os.path.join(path_inp, case), \"r\") as f:\n",
    "        for sent in f.readlines():\n",
    "            line = sent.rstrip(\"$$$\\n\")\n",
    "            tags = line.split(\"$$$\")\n",
    "            sentence = tags[0]\n",
    "            label = str(tags[1])\n",
    "            features = tags[2:]\n",
    "            if(label == \"Dissent\" or label == \"None\"):\n",
    "                continue\n",
    "            all_text += (\" \").join(features)+\"\\t\"+mapping[label]+\"\\n\" \n",
    "        f.close()\n",
    "    with open(os.path.join(path_out, case), \"w\") as f:\n",
    "        f.write(all_text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76bfee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
