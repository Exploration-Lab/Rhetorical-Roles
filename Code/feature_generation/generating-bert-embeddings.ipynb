{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Importing all required libraries\nimport torch\nfrom transformers import BertTokenizer, BertModel\nimport os\nimport time\nimport numpy as np\nimport json\nimport nltk\nfrom nltk import sent_tokenize\nfrom tqdm import tqdm\nnltk.download('punkt')\n\n## installing Transformers\n!pip install transformers\n\n## Loading the model and tokenizer\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertModel.from_pretrained(\"bert-base-uncased\")\n\n## Setting model to evaluation mode\nmodel.eval()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n## Loading data\n## Change the paths s.t it matches your file path\nIT_train_path = '/kaggle/input/rhetorical-dataset/IT_train.json'\nIT_test_path = '/kaggle/input/rhetorical-dataset/IT_test.json'\nCL_train_path = '/kaggle/input/rhetorical-dataset/CL_train.json'\nCL_test_path = '/kaggle/input/rhetorical-dataset/CL_test.json'\n\n## Loading the json data\nwith open(IT_train_path, 'r') as f:\n    train_it = json.load(f)\n    f.close()\n    \nwith open(IT_test_path, 'r') as f:\n    test_it = json.load(f)\n    f.close()\n\nwith open(CL_train_path, 'r') as f:\n    train_cl = json.load(f)\n    f.close()\n\nwith open(CL_test_path, 'r') as f:\n    test_cl = json.load(f)\n    f.close()\n\n\nit_train_files = list(train_it.keys())\ncl_train_files = list(train_cl.keys())\nit_test_files = list(test_it.keys())\ncl_test_files = list(test_cl.keys())\n\nout = 'train_it_bert_emb/' ## Give the path where you want to save the embeddings\n\n!mkdir 'train_it_bert_emb/'\n\n## Getting the embeddings for case in train_it, similarly follow for other files\n## Here we use the embedding corresponding to the [CLS] token as the sentences representation\nfor case in tqdm(train_it.keys()):\n    sentences = train_it[case]['sentences']\n    all_text = \"\"\n    start_time = time.time()\n    for idx in range(len(sentences)):\n        \n        text = sentences[idx]\n        marked_text = \"[CLS] \" + text + \" [SEP]\"\n        tokenized_text = tokenizer.tokenize(marked_text)\n        if(len(tokenized_text) > 510):\n            tokenized_text = tokenized_text[:510] + ['[SEP]']\n            \n        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n\n        segments_ids = [1] * len(tokenized_text)\n        tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n        segments_tensors = torch.tensor([segments_ids]).to(device)\n        \n        with torch.no_grad():\n            outputs = model(tokens_tensor, segments_tensors)\n        \n        emb = outputs[0].squeeze()[0].flatten().tolist()\n        \n        emb = [str(round(i,5)) for i in emb]\n        final = \" \".join(emb)\n        final += \"\\t\"+train_it[case]['complete'][idx]\n        all_text += final+\"\\n\"\n    with open(os.path.join(out, case),\"w\") as f:\n        f.write(all_text)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T13:50:46.275234Z","iopub.execute_input":"2021-09-10T13:50:46.275607Z","iopub.status.idle":"2021-09-10T13:51:19.567585Z","shell.execute_reply.started":"2021-09-10T13:50:46.275571Z","shell.execute_reply":"2021-09-10T13:51:19.563911Z"},"trusted":true},"execution_count":null,"outputs":[]}]}